Salary <- html %>% html_node("#content > div.full-width > div > section > div.datatable-wrapper.datatable-wrapper-fixed-column > table")
Salary.table<-html_text(Salary, trim=FALSE)
view(Salary.table)
View(Salary.table)
library(rvest)
library(stringr)
library(dplyr)
library(lubridate)
library(readr)
EarningEstimates <- readHTMLTable(PAYCOMtable [[1]])
EevenueEstimates <- readHTMLTable(PAYCOMtable [[2]])
EarningHistory <- readHTMLTable(PAYCOMtable [[3]])
EpsTrend <- readHTMLTable(PAYCOMtable [[4]])
EpsRevisions <- readHTMLTable(PAYCOMtable [[5]])
GrowthEst <- readHTMLTable(PAYCOMtable [[6]])
symbol = "PAYC"
url <- paste('https://finance.yahoo.com/quote/PAYC/analysis?p=PAYC',symbol,sep="")
webpage <- readLines(url)
html <- htmlTreeParse(webpage, useInternalNodes = TRUE, asText = TRUE)
PAYCOMtable <- getNodeSet(html, "//table")
EarningEstimates <- readHTMLTable(PAYCOMtable [[1]])
EevenueEstimates <- readHTMLTable(PAYCOMtable [[2]])
EarningHistory <- readHTMLTable(PAYCOMtable [[3]])
EpsTrend <- readHTMLTable(PAYCOMtable [[4]])
EpsRevisions <- readHTMLTable(PAYCOMtable [[5]])
GrowthEst <- readHTMLTable(PAYCOMtable [[6]])
library(ggplot2)
plot<-plot(PAYCOMtable)
view(plot)
library(ggplot2)
geom_density(html)
geom_density(html,aes = black)
p<-ggplot(html)
p<-ggplot(PAYCOMtable)
View(PAYCOMtable)
hist(html)
strengthcoaches<- "https://sports.usatoday.com/ncaa/salaries/football/strength"
html<- read_html(strengthcoaches)
Salary <- html %>% html_node("#content > div.full-width > div > section > div.datatable-wrapper.datatable-wrapper-fixed-column > table")
Salary.table<-html_text(Salary, trim=FALSE)
view(Salary.table)
View(Salary.table)
Salary.table<-Salary.table[[1]]
View(Salary.table)
strengthcoaches<- "https://sports.usatoday.com/ncaa/salaries/football/strength"
html<- read_html(strengthcoaches)
Salary <- html %>% html_node("#content > div.full-width > div > section > div.datatable-wrapper.datatable-wrapper-fixed-column > table") %>% html_table(fill=TRUE)
Salary.table<-html_text(Salary, trim=FALSE)
view(Salary.table)
Salary.table<-Salary.table[[1]]
Salary.table<-html_text(Salary, trim=FALSE)
View(Salary.table)
Salary.table<-Salary.table[[1]]
View(Salary)
View(Salary)
Salary$`School Pay`<- parse_number(Salary$`School Pay`)
Salary$`Total Pay`<- parse_number(Salary$`Total Pay`)
Salary$`Max Bonus` <-  parse_number(Salary$`Max Bonus`)
library(rvest)
library(readr)
library(DT)
install.packages(dt)
install.packages(DT)
install.packages('DT')
library(rvest)
library(readr)
library(DT)
Salary$`School Pay`<- parse_number(Salary$`School Pay`)
Salary$`Total Pay`<- parse_number(Salary$`Total Pay`)
Salary$`Max Bonus` <-  parse_number(Salary$`Max Bonus`)
is.na(Salary)<-Salary == "--"
Salary == Salary[-132,]
Salary = Salary[-132,]
library(ggplot2)
geom_boxplot(data=Salary)
geom_boxplot(data=Salary,aes(x = Salary$`Total Pay`, y = Salary$School))
ggplot()+
geom_boxplot(data=Salary,aes(x = Salary$`Total Pay`, y = Salary$School))
geom_boxplot(data=Salary,aes(x = Salary$`Total Pay`, y = Salary$School$SEC))
ggplot()+
geom_boxplot(data=Salary,aes(x = Salary$`Total Pay`, y = Salary$School$SEC))
ggplot()+
geom_boxplot(data=Salary,aes(x = Salary$`Total Pay`, y = Salary$Conf))
ggplot()+ geom_histogram(Salary, aes(x=Salary$`Total Pay`, y= Salary$Conf))
ggplot()+ geom_histogram(data=Salary, aes(x=Salary$`Total Pay`, y= Salary$Conf))
install.packages("DT")
install.packages("DT")
ggplot()+
geom_boxplot(data=Salary,aes(x = Salary$`Total Pay`, y = Salary$Conf))
library(ggplot2)
ggplot()+ geom_histogram(data=Salary, aes(x=Salary$`Total Pay`, y= Salary$Conf))
ggplot()+ geom_histogram(data=Salary, aes(x = Salary$`Total Pay`, y = as.factor(Salary$Conf)))
ggplot()+
geom_boxplot(data=Salary,aes(x = Salary$`Total Pay`, y = Salary$Conf))
ggplot()+ geom_histogram(data=Salary, aes(x = Salary$`Total Pay`)
ggplot()+ geom_histogram(data=Salary, aes(x = Salary$`Total Pay`))
ggplot() + geom_histogram(data=Salary, aes(x = Salary$`Total Pay`))
ggplot() + geom_histogram(data=Salary, aes(x = Salary$`Total Pay`)) +xlab("Total Pay") + ylab("") + ggtitle('Divsion 1 Strength Coach Salary')
ggplot() +
geom_dotplot(Salary, aes(x=Salary$Conf, y = Salary$Rk))
ggplot() +
geom_dotplot(Salary, aes(x=Salary$Confk))
ggplot() +
geom_dotplot(Salary)
ggplot() +
geom_point(Salary, aes(x=Salary$Conf, y = Salary$Rk))
ggplot() +
geom_point(Salary, aes(x=as.factor(Salary$Conf), y = Salary$Rk))
ggplot() +
geom_point(Salary, aes(x=as.factor(Salary$Conf), y = Salary$Rk))
ggplot(Salary, aes(x=as.factor(Salary$Conf), y = Salary$Rk)) +
geom_point()
ggplot(Salary, aes(x=as.factor(Salary$Conf), y = Salary$`Total Pay`)) +
geom_point()
ggplot(Salary, aes(x=as.factor(Salary$Conf), y = Salary$`Total Pay`)) +
geom_point() + scale_y_continuous(label=function(y) format(y, scientific = FALSE))
ggplot() + geom_histogram(data=Salary, aes(x = Salary$`Total Pay`)) +xlab("Total Pay") + ylab("Count") + ggtitle('Divsion 1 Strength Coach Salary')
ggplot() + geom_histogram(data=Salary, aes(x = Salary$`Total Pay`)) +xlab("Total Pay") + ylab("Count") + ggtitle('Divsion 1 Strength Coach Salary')
+  scale_y_continuous(label=function(y) format(y, scientific = FALSE))
ggplot() + geom_histogram(data=Salary, aes(x = Salary$`Total Pay`)) +xlab("Total Pay") + ylab("Count") + ggtitle('Divsion 1 Strength Coach Salary')
+  scale_y_continuous(label=function(x) format(x, scientific = FALSE))
ggplot() + geom_histogram(data=Salary, aes(x = Salary$`Total Pay`)) +xlab("Total Pay") + ylab("Count") + ggtitle('Divsion 1 Strength Coach Salary')
+  scale_x_discrete(label=function(x) format(x, scientific = FALSE))
ggplot(Salary, aes(x=as.factor(Salary$Conf), y = Salary$`Total Pay`)) +
geom_point() + scale_y_continuous(label=function(y) format(y, scientific = FALSE))
ggplot()+
geom_boxplot(data=Salary,aes(x = Salary$`Total Pay`, y = Salary$Conf))
ggplot() + geom_histogram(data=Salary, aes(x = Salary$`Total Pay`)) +xlab("Total Pay") + ylab("Count") + ggtitle('Divsion 1 Strength Coach Salary')
+  scale_x_discrete(label=function(x) format(x, scientific = FALSE))
ggplot() + geom_histogram(data=Salary, aes(x = Salary$`Total Pay`)) +xlab("Total Pay") + ylab("Count") + ggtitle('Divsion 1 Strength Coach Salary')
+  scale_x_discrete(label=function(x) format(x, scientific = FALSE))
library(ggplot2)
ggplot() + geom_histogram(data=Salary, aes(x = Salary$`Total Pay`)) +xlab("Total Pay") + ylab("Count") + ggtitle('Divsion 1 Strength Coach Salary')
+  scale_x_discrete(label=function(x) format(x, scientific = FALSE))
install.packages('optim.j')
install.packages('optim.jr')
view(Salary)
print(Salary)
library(mice)
library(stargazer)
library(readr)
wages<- read.csv("ModelOptimization/wages.csv")
wages<- read.csv("ModelingOptimization/wages.csv")
est.1 <- lm(logwage ~ hgc + college + tenure + tensuresq + age + married, data = df)
df.mean.imp <- df
mean.log.wage <- mean(df$log.wage, na.rm=TRUE)
df.mean.imp$logwage[is.na(df$logwage)] <-mean.log.wage
stargazer(wages)
library(readr)
wages<- read.csv("ModelingOptimization/wages.csv")
#5
wages<- wages[is.na(wages$hgc)]
wages<- wages[is.na(wages$tenue)]
#6
stargazer(wages)
wages<- read.csv("ModelingOptimization/wages.csv")
View(wages)
#5
wages<- wages[is.na(wages$hgc)]
wages<- wages[is.na(wages$tenue)]
#6
stargazer(wages)
library(readr)
wages<- read.csv("ModelingOptimization/wages.csv")
View(wages)
wages<- wages[is.na(wages$hgc)]
wages<- wages[is.na(wages$tenue)]
wages<- read.csv("ModelingOptimization/wages.csv")
View(wages)
wages<- read.csv("ModelingOptimization/wages.csv")
View(wages)
wages<- wages[is.na(wages$hgc),]
wages<- wages[is.na(wages$tenue),]
stargazer(wages)
install.packages(stargazer)
library(stargazer)
stargazer(wages)
library(stargazer)
stargazer(wages)
library(stargazer)
stargazer(wages)
wages<- wages[is.na(wages$hgc),]
wages<- wages[is.na(wages$tenue),]
library('stargazer')
stargazer(wages)
wages <- read.csv("ModelingOptimization/wages.csv")
View(wages)
wages<- wages[!is.na(wages$hgc),]
wages<- wages[!is.na(wages$tenue),]
library('stargazer')
stargazer(wages)
est.1 <- lm(logwage ~ hgc + college + tenure + tensuresq + age + married, data = wages)
stargazer(est.1)
library(nloptr)
install.packages('nloptr')
wages<- wages[!is.na(wages$hgc),]
wages<- wages[!is.na(wages$tenue),]
library('stargazer'
library('stargazer')
library('stargazer')
stargazer(wages)
View(wages)
wages <- read.csv("ModelingOptimization/wages.csv")
View(wages)
wages<- wages[!is.na(wages$hgc),]
wages<- wages[!is.na(wages$tenue),]
View(wages)
wages<- wages[!is.na(wages$hgc), ]
wages<- wages[!is.na(wages$tenue), ]
library('stargazer')
stargazer(wages)
wages <- read.csv("ModelingOptimization/wages.csv")
View(wages)
wages<- wages[!is.na(wages$hgc), ]
wages<- wages[!is.na(wages$tenue), ]
library('stargazer')
stargazer(wages)
wages <- read.csv("ModelingOptimization/wages.csv")
View(wages)
wages<- wages[!is.na(wages$hgc), ]
wages<- wages[!is.na(wages$tenue), ]
stargazer(wages)
library('stargazer')
stargazer(wages)
#4
library(readr)
wages <- read.csv("ModelingOptimization/wages.csv")
View(wages)
wages<- wages[!is.na(wages$hgc), ]
wages<- wages[!is.na(wages$tenue), ]
wages <- read.csv("ModelingOptimization/wages.csv")
wages<- wages[!is.na(wages$tenue), ]
wages <- read.csv("ModelingOptimization/wages.csv")
wages<- wages[!is.na(wages$hgc), ]
library('stargazer')
stargazer(wages)
wages<- wages[!is.na(wages$hgc), ]
wages<- wages[!is.na(wages$tenure), ]
library('stargazer')
stargazer(wages)
est.1 <- lm(logwage ~ hgc + college + tenure + tensuresq + age + married, data = wages)
stargazer(est.1)
est.1 <- lm(logwage ~ hgc + college + tenure + tenuresq + age + married, data = wages)
stargazer(est.1)
est.1 <- lm(logwage ~ hgc + college + tenure + tenure^2 + age + married, data = wages)
stargazer(est.1)
df.mean.imp <- wages
mean.log.wage <- mean(wages$log.wage, na.rm=TRUE)
df.mean.imp$logwage[is.na(wages$logwage)] <-mean.log.wage
stargazer(df.mean.imp)
est.2 <- lm(logwage ~ hgc + college + tenure +tenure^2 + age + married , data = df.mean.imp)
stargazer(est.2)
df.mar(wages)
df.mar$mar.logwage <-predict(est.1, wages.mar)
df.mar$logwage{is.na(wages$logwage)} <-df.mar$mar.logwage[is.na(df$logwage)]
est.3 <- lm(logwage ~ hgc + college + tenure +tenure^2 + age + married , data = df.mar)
df.mar(wages)
df.mar$mar.logwage <-predict(est.1, wages.mar)
df.mar$logwage{is.na(wages$logwage)} <-df.mar$mar.logwage[is.na(wages $logwage)]
est.3 <- lm(logwage ~ hgc + college + tenure +tenure^2 + age + married , data = df.mar)
est.2 <- lm(logwage ~ hgc + college + tenure +tenure^2 + age + married , data = df.mean.imp)
stargazer(est.2)
f.mar(wages)
df.mar(wages)
df.mar <- wages
df.mar$mar.logwage <-predict(est.1, wages.mar)
df.mar$mar.logwage <-predict(est.1, df.mar)
df.mar$logwage{is.na(wages$logwage)} <-df.mar$mar.logwage[is.na(wages $logwage)]
df.mar$logwage[is.na(wages$logwage)] <-df.mar$mar.logwage[is.na(wages $logwage)]
est.3 <- lm(logwage ~ hgc + college + tenure +tenure^2 + age + married , data = df.mar)
df.mice <- mice(wages, seed = 1234)
est.4 <- lm(logwage ~ hgc + college + tenure +tenure^2 + age + married , data = df.mice$data)
stargazer(est.1,est.2, est.3, title = Regression_Results)
stargazer(est.1,est.2, est.3, title = RegressionResults)
stargazer(est.1,est.2, est.3, title = RegressionResults)
stargazer(est.1,est.2, est.3, title = "RegressionResults")
library(mlr)
install.packages('mlr')
housing <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data")
names(housing) <- c("crim","zn","indus","chas","nox","rm","age","dis","rad","tax","ptratio","b","lstat","medv")
library(mlr)
library(tidyverse)
library(magrittr)
housing %<>% mutate(lmedv = log(medv),
medv = NULL,
dis2 = dis^2,
crimNOX = crim*nox)
install.packages('glmnet')
install.packages('mlr')
intstall.packages'glmnet'
install.packages('glmnet')
housing $ lmedv <- log ( housing $ medv )
housing $ medv <- NULL # drop median value
formula <- as. formula ( lmedv ~ .^3 +
poly (crim , 6) +
poly (zn , 6) +
poly (indus , 6) +
poly (nox , 6) +
poly (rm , 6) +
poly (age , 6) +
poly (dis , 6) +
poly (rad , 6) +
poly (tax , 6) +
poly ( ptratio , 6) +
poly (b, 6) +
poly (lstat , 6))
mod _ matrix <- data . frame ( model . matrix ( formula , housing ))
formula <- as.formula ( lmedv ~ .^3 +
poly (crim , 6) +
poly (zn , 6) +
poly (indus , 6) +
poly (nox , 6) +
poly (rm , 6) +
poly (age , 6) +
poly (dis , 6) +
poly (rad , 6) +
poly (tax , 6) +
poly ( ptratio , 6) +
poly (b, 6) +
poly (lstat , 6))
mod _ matrix <- data . frame ( model . matrix ( formula , housing ))
formula <- as.formula ( lmedv ~ .^3 +
poly (crim , 6) +
poly (zn , 6) +
poly (indus , 6) +
poly (nox , 6) +
poly (rm , 6) +
poly (age , 6) +
poly (dis , 6) +
poly (rad , 6) +
poly (tax , 6) +
poly ( ptratio , 6) +
poly (b, 6) +
poly (lstat , 6))
mod _ matrix <- data . frame ( model . matrix ( formula , housing ))
library(mlr)
library(glmnet)
housing $ lmedv <- log ( housing $ medv )
housing $ medv <- NULL
housing <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data")
names(housing) <- c("crim","zn","indus","chas","nox","rm","age","dis","rad","tax","ptratio","b","lstat","medv")
library(mlr)
library(tidyverse)
library(magrittr)
library(mlr)
library(tidyverse)
library(magrittr)
library(mlr)
library(tidyverse)
library(magrittr)
housing <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data")
names(housing) <- c("crim","zn","indus","chas","nox","rm","age","dis","rad","tax","ptratio","b","lstat","medv")
housing$lmedv <- log ( housing$medv )
housing$medv <- NULL
formula <- as.formula ( lmedv ~ .^3 +
poly (crim , 6) +
poly (zn , 6) +
poly (indus , 6) +
poly (nox , 6) +
poly (rm , 6) +
poly (age , 6) +
poly (dis , 6) +
poly (rad , 6) +
poly (tax , 6) +
poly ( ptratio , 6) +
poly (b, 6) +
poly (lstat , 6))
mod_matrix <- data.frame ( model.matrix ( formula , housing ))
mod_matrix[, 1] = housing$lmedv
colnames(mod_matrix )[1] = "lmedv"
# make sure to rename it otherwise MLR won ’t find it
head (mod_matrix )
# just make sure everything is hunky - dory
# Break up the data :
n <- nrow(mod_matrix )
train <- sample(n,size=.8*n)
test <- setdiff(1:n,train )
housing.train <- mod_matrix [train ,]
housing.test <- mod_matrix [test , ]
library(glmnet)
predAlg <- makeLearner("regr.glmnet")
resampleStrat <- makeResampleDesc(method = "CV", iters = 6)
# Search over penalty parameter lambda and force elastic net parameter to be 1 (LASSO)
modelParams <- makeParamSet(makeNumericParam("lambda",lower=0,upper=1),makeNumericParam("alpha",lower=1,upper=1))
# Take 50 random guesses at lambda within the interval I specified above
tuneMethod <- makeTuneControlRandom(maxit = 50L)
# Do the tuning
tunedModel <- tuneParams(learner = predAlg,
task = theTask,
resampling = resampleStrat,
measures = rmse,       # RMSE performance measure, this can be changed to one or many
par.set = modelParams,
control = tuneMethod,
show.info = TRUE)
# Apply the optimal algorithm parameters to the model
predAlg <- setHyperPars(learner=predAlg, par.vals = tunedModel$x)
# Verify performance on cross validated sample sets
resample(predAlg,theTask,resampleStrat,measures=list(rmse))
# Train the final model
finalModel <- train(learner = predAlg, task = theTask)
# Predict in test set!
prediction <- predict(finalModel, newdata = housing.test)
print(head(prediction$data))
print(get.rmse(prediction$data$truth,prediction$data$response))
# Trained parameter estimates
getLearnerModel(finalModel)$beta
#Question 7
# Search over penalty parameter lambda and force elastic net parameter to be 0 (ridge)
modelParams <- makeParamSet(makeNumericParam("lambda",lower=0,upper=1),makeNumericParam("alpha",lower=0,upper=0))
# Do the tuning again
tunedModel <- tuneParams(learner = predAlg,
task = theTask,
resampling = resampleStrat,
measures = rmse,       # RMSE performance measure, this can be changed to one or many
par.set = modelParams,
control = tuneMethod,
show.info = TRUE)
# Apply the optimal algorithm parameters to the model
predAlg <- setHyperPars(learner=predAlg, par.vals = tunedModel$x)
# Verify performance on cross validated sample sets
resample(predAlg,theTask,resampleStrat,measures=list(rmse))
# Train the final model
finalModel <- train(learner = predAlg, task = theTask)
# Predict in test set!
prediction <- predict(finalModel, newdata = housing.test)
#Print RMSE
print(get.rmse(prediction$data$truth,prediction$data$response))
#Trained parameter estimates
getLearnerModel(finalModel)$beta
#Question 8
#Search over penalty parameter lambda and force elastic net parameter to be 0 (ridge)
modelParams <- makeParamSet(makeNumericParam("lambda",lower=0,upper=1),makeNumericParam("alpha",lower=0,upper=0))
# Do the tuning again
tunedModel <- tuneParams(learner = predAlg,
task = theTask,
resampling = resampleStrat,
measures = rmse,       # RMSE performance measure, this can be changed to one or many
par.set = modelParams,
control = tuneMethod,
show.info = TRUE)
# Apply the optimal algorithm parameters to the model
predAlg <- setHyperPars(learner=predAlg, par.vals = tunedModel$x)
# Verify performance on cross validated sample sets
resample(predAlg,theTask,resampleStrat,measures=list(rmse))
# Train the final model
finalModel <- train(learner = predAlg, task = theTask)
# Predict in test set!
prediction <- predict(finalModel, newdata = housing.test)
# Print RMSE
print(get.rmse(prediction$data$truth,prediction$data$response))
# Trained parameter estimates
getLearnerModel(finalModel)$beta
modelParams <- makeParamSet(makeNumericParam("lambda",lower=0,upper=1),makeNumericParam("alpha",lower=0,upper=0))
# Do the tuning again
tunedModel <- tuneParams(learner = predAlg,
task = theTask,
resampling = resampleStrat,
measures = rmse,       # RMSE performance measure, this can be changed to one or many
par.set = modelParams,
control = tuneMethod,
show.info = TRUE)
# Apply the optimal algorithm parameters to the model
predAlg <- setHyperPars(learner=predAlg, par.vals = tunedModel$x)
# Verify performance on cross validated sample sets
resample(predAlg,theTask,resampleStrat,measures=list(rmse))
# Train the final model
finalModel <- train(learner = predAlg, task = theTask)
# Predict in test set!
prediction <- predict(finalModel, newdata = housing.test)
#Print RMSE
print(get.rmse(prediction$data$truth,prediction$data$response))
#Trained parameter estimates
getLearnerModel(finalModel)$beta
getLearnerModel(finalModel)$beta
library(mlr)
library(tidyverse)
library(magrittr)
library(glmnet)
predAlg <- makeLearner("regr.glmnet")
head (mod_matrix )
n <- nrow(mod_matrix )
train <- sample(n,size=.8*n)
test <- setdiff(1:n,train )
housing.train <- mod_matrix [train ,]
housing.test <- mod_matrix [test , ]
housing$lmedv <- log ( housing$medv )
housing$medv <- NULL
library(mlr)
library(tidyverse)
library(magrittr)
housing <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data")
names(housing) <- c("crim","zn","indus","chas","nox","rm","age","dis","rad","tax","ptratio","b","lstat","medv")
housing$lmedv <- log ( housing$medv )
housing$medv <- NULL
library(glmnet)
# Tell it a new prediction algorithm
predAlg <- makeLearner("regr.glmnet")
resampleStrat <- makeResampleDesc(method = "CV", iters = 6)
modelParams <- makeParamSet(makeNumericParam("lambda",lower=0,upper=1),makeNumericParam("alpha",lower=1,upper=1))
tuneMethod <- makeTuneControlRandom(maxit = 50L)
tunedModel <- tuneParams(learner = predAlg,
task = theTask,
resampling = resampleStrat,
measures = rmse,       # RMSE performance measure, this can be changed to one or many
par.set = modelParams,
control = tuneMethod,
show.info = TRUE)
install.packages('mlclust')
install.packages()
install.packages('mclust')
View(Salary.table)
View(Salary)
